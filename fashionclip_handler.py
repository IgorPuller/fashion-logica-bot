from fashion_clip.fashion_clip import FashionCLIP
from PIL import Image
import torch
from yandex_gpt import ask_yandex_gpt  

model = FashionCLIP('fashion-clip')

def process_photo(image_path: str) -> str:
    image = Image.open(image_path).convert("RGB")
    
    # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏ –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ —Å–ø–∏—Å–æ–∫
    embedding = model.encode_images([image], batch_size=1)
    vector = embedding[0].tolist()
    
    # –û–±—Ä–µ–∑–∞–µ–º –∏ –æ–∫—Ä—É–≥–ª—è–µ–º –¥–æ 100 –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç–∏
    vector_short = [round(x, 4) for x in vector[:100]]

    # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ–º–ø—Ç
    prompt = (
                "–ù–∞ —ç—Ç–æ–º —Ñ–æ—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞ –æ–¥–µ–∂–¥–∞. –û–ø–∏—à–∏, –∫–∞–∫–æ–π —É –Ω–µ—ë —Å—Ç–∏–ª—å. "
                "–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ñ—Ä–∞–∑—ã –≤—Ä–æ–¥–µ '—è –¥—É–º–∞—é' –∏–ª–∏ '—ç—Ç–æ—Ç –≤–µ–∫—Ç–æ—Ä'. "
                "–ì–æ–≤–æ—Ä–∏ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ,—É–≤–µ—Ä–µ–Ω–Ω–æ, –∫–∞–∫ —Å—Ç–∏–ª–∏—Å—Ç, –∞—Ä–≥—É–º–µ–Ω—Ç–∏—Ä—É–π —Å–≤–æ–π –æ—Ç–≤–µ—Ç. "
                "–ù–∞—á–Ω–∏ —Å —Ñ—Ä–∞–∑—ã: '–ù–∞ —ç—Ç–æ–º —Ñ–æ—Ç–æ ...'\n\n"
                f"–í–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {vector_short}"
            )

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ YandexGPT
    style = ask_yandex_gpt(prompt)

    return f"üß† {style}"




