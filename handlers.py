from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, ReplyKeyboardMarkup, KeyboardButton
from telegram.ext import ContextTypes
from yandex_gpt import ask_yandex_gpt
from fashionclip_handler import process_photo
import os

# Reply-–∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –≤–Ω–∏–∑—É
reply_keyboard = ReplyKeyboardMarkup(
    keyboard=[[KeyboardButton("–ù–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ")]],
    resize_keyboard=True,
    one_time_keyboard=False
)

# –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
inline_keyboard_start = InlineKeyboardMarkup([
    [
        InlineKeyboardButton("üëó –ò–ò —Å—Ç–∏–ª–∏—Å—Ç", callback_data="choose_ai"),
        InlineKeyboardButton("üí¨ –ñ–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫", url="https://t.me/igorpuller")
    ]
])

# –ü–æ–¥–º–µ–Ω—é –ò–ò —Å—Ç–∏–ª–∏—Å—Ç–∞
inline_keyboard_ai = InlineKeyboardMarkup([
    [
        InlineKeyboardButton("üì∏ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–æ—Ç–æ", callback_data="upload_photo"),
        InlineKeyboardButton("üí¨ –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å", callback_data="ask_ai")
    ],
    [
        InlineKeyboardButton("üîô –ù–∞–∑–∞–¥", callback_data="back_to_start")
    ]
])

# –ö–Ω–æ–ø–∫–∏ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–æ—Ç–æ
inline_keyboard_after_photo = InlineKeyboardMarkup([
    [
        InlineKeyboardButton("‚ûï –î–æ–±–∞–≤–∏—Ç—å –µ—â—ë —Ñ–æ—Ç–æ", callback_data="more_photos"),
        InlineKeyboardButton("ü§ñ –ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò", callback_data="analyze_photos")
    ]
])


# /start –∏–ª–∏ "–ù–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ"
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # –û—á–∏—Å—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ
    for path in context.user_data.get("photos", []):
        if os.path.exists(path):
            os.remove(path)
    context.user_data.clear()

    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç-—Å—Ç–∏–ª–∏—Å—Ç üëó",
        reply_markup=reply_keyboard
    )
    await update.message.reply_text(
        "–ö—Ç–æ —Ç–µ–±–µ –ø–æ–º–æ–∂–µ—Ç?",
        reply_markup=inline_keyboard_start
    )


# Inline-–∫–Ω–æ–ø–∫–∏
async def handle_button(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()

    if query.data == "choose_ai":
        await query.edit_message_text(
            "–¢—ã –≤—ã–±—Ä–∞–ª –ò–ò —Å—Ç–∏–ª–∏—Å—Ç–∞ ü§ñ. –ß—Ç–æ —Ö–æ—á–µ—à—å —Å–¥–µ–ª–∞—Ç—å?",
            reply_markup=inline_keyboard_ai
        )

    elif query.data == "upload_photo":
        await query.edit_message_text("–ü—Ä–∏—à–ª–∏ –º–Ω–µ —Ñ–æ—Ç–æ –æ–¥–µ–∂–¥—ã, –∫–æ—Ç–æ—Ä—É—é —Ö–æ—á–µ—à—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å üì∏")

    elif query.data == "ask_ai":
        await query.edit_message_text("–û–ø–∏—à–∏, —á—Ç–æ —Ç–µ–±–µ –Ω—É–∂–Ω–æ üëá")

    elif query.data == "back_to_start":
        await query.edit_message_text(
            "–ö—Ç–æ —Ç–µ–±–µ –ø–æ–º–æ–∂–µ—Ç?",
            reply_markup=inline_keyboard_start
        )

    elif query.data == "more_photos":
        await query.edit_message_text("–ü—Ä–∏—à–ª–∏ —Å–ª–µ–¥—É—é—â–µ–µ —Ñ–æ—Ç–æ üì∏")

    elif query.data == "analyze_photos":
        photos = context.user_data.get("photos", [])
        if not photos:
            await query.edit_message_text("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –ø—Ä–∏—à–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Ñ–æ—Ç–æ.")
            return

        await query.edit_message_text("üß† –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –æ–±—Ä–∞–∑... –ü–æ–¥–æ–∂–¥–∏ –Ω–µ–º–Ω–æ–≥–æ üëó")

        try:
            results = [process_photo(p) for p in photos]
            combined_result = "\n".join(f"{i+1}) {r}" for i, r in enumerate(results))

            await context.bot.send_message(
                chat_id=query.message.chat.id,
                text=f"–í–æ—Ç, —á—Ç–æ —è –¥—É–º–∞—é:\n{combined_result}",
                reply_markup=reply_keyboard
            )
        except Exception as e:
            await context.bot.send_message(
                chat_id=query.message.chat.id,
                text="‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."
            )
            print("FashionCLIP error:", e)

        for path in photos:
            if os.path.exists(path):
                os.remove(path)
        context.user_data.clear()


# –¢–µ–∫—Å—Ç: –≤–æ–ø—Ä–æ—Å –∫ GPT –∏–ª–∏ "–ù–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ"
async def handle_user_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text.strip().lower()

    if text == "–Ω–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ":
        await start(update, context)
        return

    try:
        response = ask_yandex_gpt(update.message.text)
        await update.message.reply_text(response, reply_markup=reply_keyboard)
    except Exception as e:
        await update.message.reply_text("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ò–ò.")
        print("YandexGPT error:", e)


# –§–æ—Ç–æ: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º —Å–ª–µ–¥—É—é—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ
async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_photos = context.user_data.setdefault("photos", [])

    photo = update.message.photo[-1]
    file = await context.bot.get_file(photo.file_id)
    file_path = f"temp_photo_{update.message.from_user.id}_{len(user_photos)}.jpg"
    await file.download_to_drive(file_path)

    user_photos.append(file_path)

    await update.message.reply_text(
        f"üì∏ –§–æ—Ç–æ {len(user_photos)} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ.",
        reply_markup=inline_keyboard_after_photo
    )


